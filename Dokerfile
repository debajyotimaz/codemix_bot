FROM python:3.10-slim

# Set environment variables
ENV PYTHONUNBUFFERED=1 \
    PYTHONDONTWRITEBYTECODE=1 \
    PIP_NO_CACHE_DIR=1 \
    PIP_DISABLE_PIP_VERSION_CHECK=1

# Set working directory
WORKDIR /app

# Install system dependencies
RUN apt-get update && apt-get install -y \
    curl \
    && rm -rf /var/lib/apt/lists/*

# Install Ollama
RUN curl -fsSL https://ollama.com/install.sh | sh

# Copy requirements and install Python dependencies
COPY requirements.txt .
RUN pip install --no-cache-dir -r requirements.txt

# Copy application files
COPY app.py .

# Expose port for Gradio
EXPOSE 7860

# Create entrypoint script directly in the Dockerfile
ENTRYPOINT ["/bin/bash", "-c", "ollama serve & \
    # Wait for Ollama to start \
    for attempt in {1..30}; do \
        if curl -s http://localhost:11434 > /dev/null; then \
            echo '✅ Ollama is ready!'; \
            break; \
        fi; \
        echo \"⏳ Waiting for Ollama to start... (Attempt $attempt/30)\"; \
        sleep 2; \
    done && \
    # Pull the model \
    ollama pull llama3.2:1b && \
    # Run the application \
    python3 app.py"]
